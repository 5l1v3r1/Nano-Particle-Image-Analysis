{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFM Particle Detection and Average Particle Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pythonvision.org/basic-tutorial/<br>http://mahotas.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mahotas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8fd4af0257b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pylab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmahotas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mla\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mahotas'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import mahotas as mh\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import linalg as la\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image to grayscale\n",
    "Code from \"https://codedump.io/share/AbxxuPPXSXZQ/1/how-can-i-convert-an-rgb-image-into-grayscale-in-python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import picture\n",
    "update filename [par] and directory [cd] as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dire=\"//Users/alex/backups/Particle Separation Analysis Photos\"\n",
    "os.chdir(dire)\n",
    "file='s4_coat_18hr_enz_1.0_00006_1.spm.png'\n",
    "par=mh.imread(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Image and Crop Scales\n",
    "verify crop image shows entire picture \n",
    "if necessary adjust [ipx] and [ipy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "imshow(par)\n",
    "gray()\n",
    "parg = rgb2gray(par)    #convert image from rgb to gray\n",
    "figure()\n",
    "ipx=2015   #AFM exported image pixel count\n",
    "ipy=2015   #AFM exported image pixel count\n",
    "pargc=parg[2:ipy,2:ipx] # crop image \n",
    "imshow(pargc)  #  gray cropped image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scales From Image\n",
    "Read and input scale values from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars=8     # barscale length          |  um\n",
    "hl=413.7  # low height scale limit   |  nm\n",
    "hh=-91.9  # high height scale limit  |  nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Scale bar from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imshow(parg[2015:2030,1580:2050])\n",
    "scal=parg[2030,0:2000]\n",
    "bar=np.count_nonzero(scal-255)\n",
    "pc=bars/bar #pixel to um scale conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image to black and white using bimodal histogram distribution separation \n",
    "pixels and background\n",
    "initial bimodal threshold, observe any adjustments necessary such as adjusting background or minimizing high pixel values (changes height but not area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T=mh.thresholding.otsu(pargc.astype(uint8))  #otsu bi-modal histogram thresholding  https://en.wikipedia.org/wiki/Otsu%27s_method\n",
    "figure()\n",
    "imshow(pargc>T,extent=[0,pc*ipx,0,pc*ipy])\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram analysis for Thresholding\n",
    "verify that the calculated threshold is appropriate. This can have errors when the distribution is not bi modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=hist(pargc.ravel(),bins=int(255/2),fc='k', ec='k')\n",
    "xlabel('Intensity')\n",
    "ylabel('Pixel Count')\n",
    "ylim([0,40000])\n",
    "show()\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi gaussian fit code from:\n",
    "#https://stackoverflow.com/questions/35990467/fit-two-gaussians-to-a-histogram-from-one-set-of-data-pytho\n",
    "\n",
    "xh=h[1]\n",
    "yh=np.append(0,h[0])\n",
    "\n",
    "plt.plot(xh,yh)\n",
    "show()\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "#x=(x[1:]+x[:-1])/2 # for len(x)==len(y)\n",
    "\n",
    "def gauss(x,mu,sigma,A):\n",
    "    return A*exp(-(x-mu)**2/2/sigma**2)\n",
    "\n",
    "def nmodal(x,mu1,sigma1,A1,mu2,sigma2,A2,mu3,sigma3,A3,mu4,sigma4,A4,mu5,sigma5,A5):#mu3,sigma3,A3,mu4,sigma4,A4,\n",
    "    return gauss(x,mu1,sigma1,A1)+gauss(x,mu2,sigma2,A2)+gauss(x,mu3,sigma3,A3)+gauss(x,mu4,sigma4,A4)+gauss(x,mu5,sigma5,A5)#+gauss(x,mu3,sigma3,A3)+gauss(x,mu4,sigma4,A4)\n",
    "\n",
    "plt.plot(xh,nmodal(xh,8,1,1.4e6,20,1,5.5e5,100,20,4.5e3,160,20,3e3,271,3,4e10),xh,yh)\n",
    "ylim([0,40000])\n",
    "show()\n",
    "\n",
    "expected=(8,1,1.4e6,20,1,5.5e5,26,6,4.5e4,47,1,1e4,271,3,4e10)#100,50,5.5e3,160,50,3e3,\n",
    "params,cov=curve_fit(nmodal,xh,yh,expected)\n",
    "sigma=sqrt(diag(cov))\n",
    "plot(xh,nmodal(xh,*params),color='red',lw=3,label='model')\n",
    "legend()\n",
    "print(params,'\\n',sigma) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual thresholding\n",
    "In the case that there is multimodal data (>2)\n",
    "If there are large particles (peak on histogram above at 255) can shrink data to maximum size of rest of data to remove effect on threshold [1st line]\n",
    "\n",
    "move all backgroud data to 0 manually using [Ts1] from above histogram\n",
    "Adjust \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ti=255                                                 #Initial upper threshold \n",
    "pargc[pargc>Ti]=Ti                                  #minimizing large data points to not skew histogram\n",
    "pargcf = mh.gaussian_filter(pargc, 8).astype('uint8')  #gaussian filter for noise reduction\n",
    "Ts1=30                                                #manual filter limit based upon histogram above\n",
    "\n",
    "\n",
    "pargcf[pargcf<Ts1]=0\n",
    "\n",
    "\n",
    "#multimodal fit (>2)\n",
    "pargcfs=np.copy(pargcf)  #smaller range (2 particle peaks)\n",
    "pargcfb=np.copy(pargcf)  #bigger range\n",
    "\n",
    "#pargcfs[pargcf>1*T]=Ts1      #to account for need of multimodal(>2) fit, which is not capable in python with mahotas or opencv \n",
    "Ts = 0.5*mh.thresholding.otsu(pargcfs,1)\n",
    "\n",
    "pargcfb[pargcf<T]=0\n",
    "#pargcfb[pargcf>0.2*T]=0\n",
    "\n",
    "Tb = mh.thresholding.otsu(pargcfb,1)\n",
    "#pargcfb[pargcf<Ts]=pargcf[pargcf<Ts]\n",
    "#for non monodispersed and multpile base (?) sized particles\n",
    "\n",
    "#pargcfs=np.copy(pargcfb)\n",
    "#Ts=np.copy(Tb)\n",
    "\n",
    "# In the case of bimodal distribution use the below 2 lines\n",
    "#pargcfs=pargcf\n",
    "#Ts=T\n",
    "\n",
    "figure()\n",
    "imshow(pargcfs ,extent=[0,pc*ipx,0,pc*ipy])\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n",
    "\n",
    "print(Ts,Tb)\n",
    "figure()\n",
    "imshow(pargcfb,extent=[0,pc*ipx,0,pc*ipy])\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph a) Minimized peak heights for the large particles in an attempt to make a bimodal histogram\n",
    "\n",
    "Graph b) Smoothed background removing smaller particles for a bimodal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification that the data is thresholded properly\n",
    "\n",
    "Adjust the thresholded value if graph is not representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled,nr_objects = mh.label(pargcfs > 0.7*Ts)  #all pixels in \"one\" particle same value\n",
    "print(nr_objects)\n",
    "imshow(labeled,extent=[0,pc*ipx,0,pc*ipy])\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n",
    "\n",
    "figure()    \n",
    "imshow(mh.overlay(pargcf,labeled),extent=[0,pc*ipx,0,pc*ipy])\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Fit to isolate particles\n",
    "check Gaussian pixel fit to identify particles correctly. A good starting point is 8, with other common values (from experience) being 12,16,24,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf=5  # gaussian pixel fit\n",
    "pargcfs = mh.gaussian_filter(pargcfs, gf).astype('uint8')\n",
    "Bc_ = np.ones((3,3))\n",
    "rmaxg = mh.regmax(pargcfs,Bc=Bc_)\n",
    "\n",
    "imshow(mh.overlay(pargcfs, rmaxg), extent=[0,pc*ipx,0,pc*ipy])\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n",
    "\n",
    "\n",
    "figure()\n",
    "imshow(rmaxg, extent=[0,pc*ipx,0,pc*ipy])\n",
    "gray()\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distance Transformation and watershed\n",
    "reformating particles into spheres (distance transform) followed by inversion to set up watershed (particle identification and labeling)\n",
    "\n",
    "may need to adjust Threshold value [Ta] and [thr] via dist.mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spots,n_spots = mh.label(rmaxg)\n",
    "print(n_spots)\n",
    "\n",
    "Ta = 1*mh.thresholding.otsu(pargcfs,0)\n",
    "h=hist(pargcfs.ravel(),bins=int(255/10),fc='k', ec='k')\n",
    "xlabel('Intensity')\n",
    "ylabel('Pixel Count')\n",
    "show()\n",
    "print(Ta)\n",
    "dist = mh.distance(pargcfs > 0.05*Ta)   ###pargcfs\n",
    "\n",
    "dist = dist.max() - dist#\n",
    "dist -= dist.min()# inverting color\n",
    "dist = dist/float(dist.ptp()) * 255\n",
    "dist = dist.astype(np.uint8)\n",
    "dist=mh.stretch(dist,0,255)\n",
    "figure()\n",
    "imshow(dist, extent=[0,pc*ipx,0,pc*ipy])\n",
    "jet()\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()                                                                             #1\n",
    "\n",
    "th=np.median(dist)#.mean()\n",
    "thr=(dist < th)  #not accurate to particles detected(?) but matches dist graph well\n",
    "print(th)\n",
    "areas = 0.9*mh.cwatershed(dist, labeled)#spots) #labeled\n",
    "areas = areas*thr\n",
    "print(type(areas))\n",
    "figure()\n",
    "imshow(areas, extent=[0,pc*ipx,0,pc*ipy])                                 #2\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n",
    "\n",
    "\n",
    "figure()\n",
    "imshow(mh.overlay(pargc,rmaxg), extent=[0,pc*ipx,0,pc*ipy])               #3\n",
    "gray()\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(areas))\n",
    "np.unique(areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Distribution\n",
    "Calculation of size and surface density calculation\n",
    "Verify labeled areas correlate to above thresholded image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-21f12118a802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBc1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_seeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mareas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#seeds=np.copy(spots)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#n_seeds=np.copy(n_spots)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mh' is not defined"
     ]
    }
   ],
   "source": [
    "Bc1= np.ones((9,9))\n",
    "seeds,n_seeds = mh.label(areas,Bc=Bc1)\n",
    "#seeds=np.copy(spots)\n",
    "#n_seeds=np.copy(n_spots)\n",
    "\n",
    "sp=np.where(seeds)\n",
    "imshow(seeds, extent=[0,pc*ipx,0,pc*ipy])\n",
    "jet()\n",
    "xlabel('Distance / $\\mu$m')\n",
    "ylabel('Distance / $\\mu$m')\n",
    "show()\n",
    "\n",
    "locg=mh.center_of_mass(pargc,seeds)       # location for each seed\n",
    "locg=locg.astype(int)\n",
    "\n",
    "sg = mh.labeled.labeled_size(seeds)\n",
    "pr_mean=np.sqrt(mean(sg[1:])/np.pi)*pc   #average particle radius assuming circular shape\n",
    "sg=np.sqrt(sg[1:]/np.pi)*pc              #particle radius assuming circular shape\n",
    "pr_med=np.median(sg)\n",
    "pr_std=np.sqrt(std(sg[1:])/np.pi)*pc\n",
    "print('average particle radius: %1.4e +- %1.4e um'%(pr_mean,pr_std))\n",
    "print('median particle radius: %1.4e +- %1.4e um'%(pr_med,pr_std))\n",
    "print('number of particles: %.0f'%n_seeds)\n",
    "#hist(seeds.ravel()):\n",
    "figure()\n",
    "hist(sg, bins=40)#,range=(0,10));\n",
    "xlabel('Particle radius / um')\n",
    "ylabel('Particle count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Separation Analysis\n",
    "Calculating the partilce separation\n",
    "Normalization and pythagorean separation show extremely close calculation fo particle separation so that they are in agreement with one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmaxg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-812496054598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxsg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mysg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrmaxg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxsg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpc\u001b[0m  \u001b[1;31m#x image length    um\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mysg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpc\u001b[0m  \u001b[1;31m#y image length    um\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#particle density\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Particle density:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'particles/um^2'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rmaxg' is not defined"
     ]
    }
   ],
   "source": [
    "xsg,ysg=rmaxg.shape\n",
    "x=xsg*pc  #x image length    um\n",
    "y=ysg*pc  #y image length    um\n",
    "rho=n_seeds/(y*x)   #particle density\n",
    "print('Particle density:',rho,'particles/um^2') #\n",
    "xa=np.linspace(0,x,ipx)\n",
    "ya=np.linspace(0,y,ipy)\n",
    "rmaxp=np.where(rmaxg)\n",
    "\n",
    "dmi=np.empty(len(locg[:,0])-1) #initialize empty array of minimum particle distance for each particle\n",
    "d=np.empty([len(locg[:,0])-1,len(locg[:,0])-1])\n",
    "da=np.empty(len(locg[:,0])-1)\n",
    "a=0\n",
    "print(locg)\n",
    "for s in range(0,len(locg[:,0])-1):\n",
    "    dm=np.empty(len(locg[:,0])-1)   #distance between particle S and every other particle\n",
    "    for ss in range(0,len(locg[:,0])-1):\n",
    "\n",
    "        d[s,ss]=norm(locg[s,:]-locg[ss,:])\n",
    "        dm[ss]=np.sqrt(np.square(xa[locg[s,0]]-xa[locg[ss,0]])+np.square(ya[locg[s,1]]-ya[locg[ss,1]]))\n",
    "        \n",
    "        if dm[ss]>3: #thresholded value\n",
    "            xloc[a]=locg[ss,0]\n",
    "            a=a+1\n",
    "\n",
    "    dmi[s]=np.amin(dm[np.nonzero(dm)])\n",
    "    da[s]=np.amin(d[s,np.nonzero(d[s,:])])\n",
    "\n",
    "da_mean = np.mean(da)*pc\n",
    "da_std = np.std(da)*pc\n",
    "print('Average particle separation is: %1.4e +- %1.4e um'%(np.mean(dmi),np.std(dmi)))#%1.4e cm-3' % (Pb)\n",
    "print('Average minimum particle norm is: %1.4e +- %1.4e um'%(da_mean,da_std))\n",
    "matshow(d);\n",
    "jet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "separation-particle size ratio: 2.7339141047586843\n"
     ]
    }
   ],
   "source": [
    "spr=np.mean(dmi)/np.mean(sg)\n",
    "print('separation-particle size ratio:',spr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssx=pc*ipx\n",
    "ssy=pc*ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pause before storing results and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a4bd803b6750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Press enter to continue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input('Press enter to continue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store results and parameters of results in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/alex/backups/Particle Separation Analysis Photos/Particle Analysis.csv\")\n",
    "dfp=pd.read_csv(\"/Users/alex/backups/Particle Separation Analysis Photos/Particle Analysis Parameters.csv\")\n",
    "\n",
    "df=df.append({'dir':dire,'file':file,'pr_mean':pr_mean,'pr_med':pr_med,'pr_std':pr_std,'da_mean':da_mean,'da_std':da_std,'rho':rho,'spr':spr,'ssx':ssx,'ssy':ssy,'n_seeds':n_seeds},ignore_index=True)\n",
    "dfp=dfp.append({'dir':dire,'file':file,'Ti':Ti,'Ts1':Ts1,'Ts':Ts,'Tb':Tb,'gf':gf,'Ta':Ta,'thr':th},ignore_index=True)\n",
    "print(df)\n",
    "print(dfp)\n",
    "df.to_csv(\"/Users/alex/backups/Particle Separation Analysis Photos/Particle Analysis.csv\")\n",
    "dfp.to_csv(\"/Users/alex/backups/Particle Separation Analysis Photos/Particle Analysis Parameters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
